{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "004d328d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using MLDatasets\n",
    "using ImageCore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d509f8",
   "metadata": {},
   "source": [
    "# Grokking Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0479ada7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.022499999999999975"
     ]
    }
   ],
   "source": [
    "weight = 0.1\n",
    "lr = 0.01\n",
    "\n",
    "function neural_network(input, weight)\n",
    "    prediction = input * weight\n",
    "end\n",
    "\n",
    "number_of_toes = [8.5]\n",
    "win_or_lose_binary = [1]  # Won!\n",
    "\n",
    "input = number_of_toes[1]\n",
    "t = win_or_lose_binary[1]\n",
    "\n",
    "pred = neural_network(input, weight)\n",
    "error = (pred - t) ^ 2\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c293725",
   "metadata": {},
   "source": [
    "### Hot and cold learning (Simple but Inefficient)\n",
    "\n",
    "\n",
    "Hot and cold learning means wiggling the weights to see which direction reduces the error\n",
    "the most, moving the weights in that direction, and repeating until the error gets to 0.\n",
    "\n",
    "Well, you try both up and down and see which one reduces the error!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b44232",
   "metadata": {},
   "source": [
    "### Gradient descent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bac8eba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11275"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = 0.1\n",
    "\n",
    "function neural_network(input, weight)\n",
    "    prediction = input * weight\n",
    "end\n",
    "\n",
    "number_of_toes = [8.5]\n",
    "win_or_lose_binary = [1]  # Won!\n",
    "\n",
    "input = number_of_toes[1]\n",
    "goal_pred = win_or_lose_binary[1]\n",
    "\n",
    "pred = neural_network(input, weight)\n",
    "error = (pred - goal_pred) ^ 2\n",
    "∇ = pred - goal_pred\n",
    "weight∇ = input * ∇\n",
    "α = 0.01\n",
    "weight -= weight∇ * α"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "913de45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1\n",
      "ϵ = 1.0\n",
      "weight = 0.0\n",
      "pred = 0.0\n",
      "=== Epoch 2\n",
      "ϵ = 0.03609999999999998\n",
      "weight = 0.9\n",
      "pred = 0.81\n",
      "=== Epoch 3\n",
      "ϵ = 0.0013032100000000015\n",
      "weight = 1.071\n",
      "pred = 0.9639\n",
      "=== Epoch 4\n",
      "ϵ = 4.704588100000082e-5\n",
      "weight = 1.1034899999999999\n",
      "pred = 0.9931409999999999\n",
      "=== Epoch 5\n",
      "ϵ = 1.698356304100287e-6\n",
      "weight = 1.1096631\n",
      "pred = 0.9986967899999999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.110835989"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight, goad_pred, input = (0.0, 0.8, 0.9)\n",
    "\n",
    "for i in 1:5\n",
    "    pred = input * weight\n",
    "    ϵ = (pred - goal_pred) ^ 2\n",
    "    println(\"=== Epoch $(i)\")\n",
    "    @show ϵ weight pred\n",
    "    ∇ = pred - goal_pred\n",
    "    weight∇ = input * ∇\n",
    "    weight -= weight∇\n",
    "end\n",
    "\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1ccd9860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1\n",
      "ϵ = 1.0\n",
      "weight = 0.0\n",
      "pred = 0.0\n",
      "∇ = -1.0\n",
      "=== Epoch 2\n",
      "ϵ = 0.354025\n",
      "weight = 0.45\n",
      "pred = 0.405\n",
      "∇ = -0.595\n",
      "=== Epoch 3\n",
      "ϵ = 0.12533370062500002\n",
      "weight = 0.71775\n",
      "pred = 0.645975\n",
      "∇ = -0.35402500000000003\n",
      "=== Epoch 4\n",
      "ϵ = 0.0443712633637656\n",
      "weight = 0.87706125\n",
      "pred = 0.789355125\n",
      "∇ = -0.21064487499999995\n",
      "=== Epoch 5\n",
      "ϵ = 0.015708536512357138\n",
      "weight = 0.97185144375\n",
      "pred = 0.874666299375\n",
      "∇ = -0.12533370062500004\n",
      "=== Epoch 6\n",
      "ϵ = 0.0055612146387872445\n",
      "weight = 1.02825160903125\n",
      "pred = 0.9254264481281249\n",
      "∇ = -0.07457355187187509\n",
      "=== Epoch 7\n",
      "ϵ = 0.0019688090124966493\n",
      "weight = 1.0618097073735937\n",
      "pred = 0.9556287366362344\n",
      "∇ = -0.04437126336376562\n",
      "=== Epoch 8\n",
      "ϵ = 0.0006970076106491235\n",
      "weight = 1.0817767758872883\n",
      "pred = 0.9735990982985595\n",
      "∇ = -0.026400901701440493\n",
      "=== Epoch 9\n",
      "ϵ = 0.0002467581193600543\n",
      "weight = 1.0936571816529366\n",
      "pred = 0.984291463487643\n",
      "∇ = -0.01570853651235704\n",
      "=== Epoch 10\n",
      "ϵ = 8.73585432064442e-5\n",
      "weight = 1.1007260230834972\n",
      "pred = 0.9906534207751475\n",
      "∇ = -0.009346579224852491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.104931983734681"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight, goad_pred, input = (0.0, 0.8, 0.9)\n",
    "α = 0.5\n",
    "\n",
    "for i in 1:10\n",
    "    pred = input * weight\n",
    "    ϵ = (pred - goal_pred) ^ 2\n",
    "    println(\"=== Epoch $(i)\")\n",
    "    ∇ = pred - goal_pred\n",
    "    @show ϵ weight pred ∇\n",
    "    weight∇ = input * ∇\n",
    "    weight -= (α * weight∇)\n",
    "end\n",
    "\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "77923814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wsum (generic function with 1 method)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsum(a, b) = sum(a .* b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "024c4dc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_network (generic function with 1 method)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_network(input, weights)\n",
    "    wsum(input, weights)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be1e7584",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1\n",
      "ϵ = 0.00122500000000001\n",
      "α = 0.003\n",
      "∇ = 0.03500000000000014\n",
      "weights = [0.09745000000000001, 0.099805, 0.09964]\n",
      "pred = 1.0350000000000001\n",
      "=== Epoch 2\n",
      "ϵ = 0.00016297713906250229\n",
      "α = 0.003\n",
      "∇ = 0.01276625000000009\n",
      "weights = [0.09496502500000001, 0.09961038025, 0.099281296]\n",
      "pred = 1.01276625\n",
      "=== Epoch 3\n",
      "ϵ = 7.944130406129285e-5\n",
      "α = 0.003\n",
      "∇ = -0.00891298513749983\n",
      "weights = [0.0925434168625, 0.09941614000851251, 0.09892388333440001]\n",
      "pred = 0.9910870148625002\n",
      "=== Epoch 4\n",
      "ϵ = 0.0009031110235428149\n",
      "α = 0.003\n",
      "∇ = -0.03005180566193677\n",
      "weights = [0.09018355973250626, 0.09922227853549591, 0.09856775735439617]\n",
      "pred = 0.9699481943380632\n"
     ]
    }
   ],
   "source": [
    "toes = [8.5 , 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2 , 1.3, 0.5, 1.0]\n",
    "\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "\n",
    "weights = [0.1, 0.1, 0.1]\n",
    "input = [toes[1], wlrec[1], nfans[1]]\n",
    "\n",
    "for i in 1:4\n",
    "    pred = neural_network(input, weights)\n",
    "    ∇ = pred - win_or_lose_binary[1]\n",
    "    ϵ = ∇ ^ 2\n",
    "    α = 0.003\n",
    "    weight_∇ = input .* weights\n",
    "    weights = weights .- (weight_∇ .* α)\n",
    "    println(\"=== Epoch $(i)\")\n",
    "    @show ϵ α ∇ weights pred\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b06c9df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load full training set\n",
    "train_x, train_y = MNIST.traindata();\n",
    "\n",
    "# load full test set\n",
    "test_x,  test_y  = MNIST.testdata();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b77c8d",
   "metadata": {},
   "source": [
    "## Building a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "a1a64008",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1\n",
      "total_error = 2.6561231104\n",
      "=== Epoch 2\n",
      "total_error = 0.9628701776715985\n",
      "=== Epoch 3\n",
      "total_error = 0.5509165866836797\n",
      "=== Epoch 4\n",
      "total_error = 0.36445836852222424\n",
      "=== Epoch 5\n",
      "total_error = 0.2516768662079895\n",
      "=== Epoch 6\n",
      "total_error = 0.17797575048089034\n",
      "=== Epoch 7\n",
      "total_error = 0.12864460733422164\n",
      "=== Epoch 8\n",
      "total_error = 0.09511036950476208\n",
      "=== Epoch 9\n",
      "total_error = 0.07194564247043436\n",
      "=== Epoch 10\n",
      "total_error = 0.05564914990717743\n",
      "=== Epoch 11\n",
      "total_error = 0.04394763937673939\n",
      "=== Epoch 12\n",
      "total_error = 0.035357967050948465\n",
      "=== Epoch 13\n",
      "total_error = 0.02890700056547436\n",
      "=== Epoch 14\n",
      "total_error = 0.023951660591138853\n",
      "=== Epoch 15\n",
      "total_error = 0.020063105176016144\n",
      "=== Epoch 16\n",
      "total_error = 0.016952094519447087\n",
      "=== Epoch 17\n",
      "total_error = 0.014420818295271236\n",
      "=== Epoch 18\n",
      "total_error = 0.012331739998443648\n",
      "=== Epoch 19\n",
      "total_error = 0.010587393171639842\n",
      "=== Epoch 20\n",
      "total_error = 0.009117233405426495\n"
     ]
    }
   ],
   "source": [
    "weights = [0.5, 0.48, -0.7]\n",
    "α = 0.1\n",
    "\n",
    "streetlights = [1 0 1; 0 1 1; 0 0 1; 1 1 1; 0 1 1; 1 0 1]\n",
    "walk_vs_stop = [0 1 0 1 1 0]\n",
    "\n",
    "for i in 1:20\n",
    "    println(\"=== Epoch $(i)\")\n",
    "    total_error = 0\n",
    "    for (j, row) in enumerate(eachrow(streetlights))\n",
    "        goal_pred = walk_vs_stop[j]\n",
    "        pred = wsum(row, weights)\n",
    "        error = (goal_pred - pred) ^ 2\n",
    "        total_error += error\n",
    "        ∇ = pred - goal_pred\n",
    "        weights = weights .- (α .* (row .* ∇ ))\n",
    "    end\n",
    "    @show total_error\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d0c768",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "8a53a5cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1\n",
      "total_error = 5.402956997437806\n",
      "=== Epoch 2\n",
      "total_error = 1.9251309373400844\n",
      "=== Epoch 3\n",
      "total_error = 0.8428460921954337\n",
      "=== Epoch 4\n",
      "total_error = 0.3566410966847956\n",
      "=== Epoch 5\n",
      "total_error = 0.1603395974073259\n",
      "=== Epoch 6\n",
      "total_error = 0.09178367336855531\n",
      "=== Epoch 7\n",
      "total_error = 0.05437860206554075\n",
      "=== Epoch 8\n",
      "total_error = 0.034496313133492953\n",
      "=== Epoch 9\n",
      "total_error = 0.020195104522025862\n",
      "=== Epoch 10\n",
      "total_error = 0.011630918423517662\n",
      "=== Epoch 11\n",
      "total_error = 0.006646104407267865\n",
      "=== Epoch 12\n",
      "total_error = 0.003799964968302484\n",
      "=== Epoch 13\n",
      "total_error = 0.0021920647615691793\n",
      "=== Epoch 14\n",
      "total_error = 0.001286041394114329\n",
      "=== Epoch 15\n",
      "total_error = 0.0007730115285601523\n",
      "=== Epoch 16\n",
      "total_error = 0.0004790285056091288\n",
      "=== Epoch 17\n",
      "total_error = 0.0003074174328568179\n",
      "=== Epoch 18\n",
      "total_error = 0.00020475183342557235\n",
      "=== Epoch 19\n",
      "total_error = 0.00014148576942701882\n",
      "=== Epoch 20\n",
      "total_error = 0.00010117794922473382\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 4\n",
    "weights₀ = 2 * rand(Float64, (3, hidden_size)) .- 1\n",
    "weights₁ = 2 * rand(Float64, (hidden_size, 1)) .- 1\n",
    "α = 0.2\n",
    "\n",
    "relu(x) = (x > 0) * x\n",
    "\n",
    "relu2deriv(output) = output > 0\n",
    "\n",
    "streetlights = [1 0 1; 0 1 1; 0 0 1; 1 1 1; 0 1 1; 1 0 1]\n",
    "walk_vs_stop = [0 1 0 1 1 0]\n",
    "\n",
    "for epoch in 1:20\n",
    "    println(\"=== Epoch $(epoch)\")\n",
    "    total_error = 0\n",
    "    for (i, row) in enumerate(eachrow(streetlights))\n",
    "        layer₀ = row'\n",
    "        goal_pred = walk_vs_stop[i]\n",
    "        layer₁ = relu.(layer₀ * weights₀)\n",
    "        \n",
    "        layer₂ = sum(layer₁ * weights₁)\n",
    "        \n",
    "        total_error += (layer₂ - goal_pred) ^ 2\n",
    "        layer₂∇ = layer₂ - goal_pred\n",
    "        \n",
    "        layer₁∇ = (layer₂∇ * weights₁') .* relu2deriv.(layer₁)\n",
    "        weights₁ -= α * (layer₁' * layer₂∇)\n",
    "        weights₀ -= α * (layer₀' * layer₁∇)\n",
    "    end\n",
    "    @show total_error\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b02d57",
   "metadata": {},
   "source": [
    "### Three-layer network on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bc9a0a42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 50\n",
      "error = 0.43363680539958976\n",
      "correct = 0.7665\n",
      "test_error = 0.33530167442822706\n",
      "test_correct = 0.8524\n",
      "=== Epoch 100\n",
      "error = 0.38558283436807195\n",
      "correct = 0.8065\n",
      "test_error = 0.3015177073133007\n",
      "test_correct = 0.8742\n",
      "=== Epoch 150\n",
      "error = 0.34570466776592645\n",
      "correct = 0.838\n",
      "test_error = 0.29056989247280834\n",
      "test_correct = 0.88\n",
      "=== Epoch 200\n",
      "error = 0.3309050307048\n",
      "correct = 0.858\n",
      "test_error = 0.28204327293173254\n",
      "test_correct = 0.8847\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using MLDatasets\n",
    "using ImageCore\n",
    "using Distributions\n",
    "\n",
    "p = Binomial(1, 0.5)\n",
    "\n",
    "one_hot_encoding(x) = Flux.onehotbatch(x, 0:9)\n",
    "train_size = 2000\n",
    "\n",
    "train_x, train_y = MNIST.traindata(1:train_size);\n",
    "test_x, test_y  = MNIST.testdata();\n",
    "\n",
    "labels = one_hot_encoding(train_y)\n",
    "test_labels = one_hot_encoding(test_y)\n",
    "\n",
    "α, iterations =  0.001, 201\n",
    "hidden_size, pixels_per_image, num_labels = 40, 28 * 28, 10\n",
    "batch_size = 100\n",
    "\n",
    "weights₀ = 0.2 * rand(Float16, (pixels_per_image, hidden_size)) .- 0.1\n",
    "weights₁ = 0.2 * rand(Float16, (hidden_size, num_labels)) .- 0.1\n",
    "\n",
    "relu(x) = (x > 0) * x\n",
    "\n",
    "relu2deriv(output) = output > 0\n",
    "\n",
    "for epoch in 1:iterations\n",
    "    error, correct = 0, 0\n",
    "    for i in 1:train_size\n",
    "        layer₀ = reshape(train_x[:, :, i], 1, 28*28)  # Input\n",
    "        label = reshape(labels[:, i], 1, 10)\n",
    "\n",
    "        layer₁ = relu.(layer₀ * weights₀)\n",
    "        dropout_mask = rand(p, size(layer₁))\n",
    "        layer₁ = (layer₁ .* dropout_mask) * 2\n",
    "\n",
    "        layer₂ = layer₁ * weights₁\n",
    "        error += sum(( label - layer₂ ) .^ 2)\n",
    "        correct += convert(Int, argmax(layer₂) == argmax(label))\n",
    "\n",
    "        layer₂∇ = label - layer₂\n",
    "        layer₁∇ = (layer₂∇ * weights₁') .* relu2deriv.(layer₁)\n",
    "        layer₁∇ = layer₁∇ .* dropout_mask\n",
    "\n",
    "        weights₁ += α * (layer₁' * layer₂∇)\n",
    "        weights₀ += α * (layer₀' * layer₁∇)\n",
    "    end\n",
    "\n",
    "    if rem(epoch, 50) == 0\n",
    "        println(\"=== Epoch $(epoch)\")\n",
    "        test_size = 10000\n",
    "        correct /= train_size\n",
    "        error /= train_size\n",
    "        @show error correct\n",
    "        test_error, test_correct = (0.0, 0)\n",
    "        for i in 1:test_size\n",
    "            layer₀ = reshape(test_x[:, :, i], 1, 28*28)\n",
    "            label = reshape(test_labels[:, i], 1, 10)\n",
    "            layer₁ = relu.(layer₀ * weights₀)\n",
    "            layer₂ = layer₁ * weights₁\n",
    "            test_error += sum(( label - layer₂ ) .^ 2)\n",
    "            test_correct += convert(Int, argmax(layer₂) == argmax(label))\n",
    "        end\n",
    "        test_error /= test_size\n",
    "        test_correct /= test_size\n",
    "        @show test_error test_correct\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "32f09378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict = Any[3, 1, 5, 3, 1, 8, 4, 9, 7, 7, 1, 6, 6, 0, 8, 2]\n",
      "label = Any[3, 1, 3, 3, 1, 8, 4, 9, 7, 7, 7, 6, 6, 0, 8, 2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "28×448 MosaicView{Gray{N0f8}, 4, Base.ReshapedArray{Gray{N0f8}, 4, PaddedView{Gray{N0f8}, 3, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}, Base.OneTo{Int64}}, StackViews.StackView{Gray{N0f8}, 3, 3, Vector{OffsetArrays.OffsetMatrix{Gray{N0f8}, PaddedView{Gray{N0f8}, 2, Tuple{UnitRange{Int64}, UnitRange{Int64}}, Base.ReinterpretArray{Gray{N0f8}, 2, N0f8, Matrix{N0f8}, true}}}}}}, Tuple{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}, Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}}}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Images\n",
    "using Flux: onecold\n",
    "\n",
    "function test_model(image)\n",
    "    layer₀ = reshape(image, 1, 28*28)\n",
    "    layer₁ = relu.(layer₀ * weights₀)\n",
    "    layer₂ = layer₁ * weights₁\n",
    "    argmax(layer₂)[2] - 1\n",
    "end\n",
    "\n",
    "n = rand(1:10000, 16)\n",
    "grid = [\n",
    "    MNIST.convert2image(test_x[:, :, i])\n",
    "    for i in n\n",
    "]\n",
    "predict, label = [], []\n",
    "\n",
    "for i in n\n",
    "    push!(predict, test_model(test_x[:, :, i]))\n",
    "    push!(label, onecold(test_labels[:, i]) - 1)\n",
    "end\n",
    "\n",
    "@show predict label\n",
    "\n",
    "mosaicview(grid; nrow=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fe9d65",
   "metadata": {},
   "source": [
    "### Batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "16e0fb1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 50\n",
      "error = 0.37425603499667937\n",
      "correct = 0.853\n",
      "test_error = 0.4191010159136493\n",
      "test_correct = 0.7974\n",
      "=== Epoch 100\n",
      "error = 0.2899693723800722\n",
      "correct = 0.912\n",
      "test_error = 0.3593513258346201\n",
      "test_correct = 0.8316\n",
      "=== Epoch 150\n",
      "error = 0.25272370040260533\n",
      "correct = 0.93\n",
      "test_error = 0.33472305231706106\n",
      "test_correct = 0.8412\n",
      "=== Epoch 200\n",
      "error = 0.214534084315744\n",
      "correct = 0.959\n",
      "test_error = 0.322661942996808\n",
      "test_correct = 0.8472\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using MLDatasets\n",
    "using ImageCore\n",
    "using Distributions\n",
    "\n",
    "one_hot_encoding(x) = Flux.onehotbatch(x, 0:9)\n",
    "train_size = 1000\n",
    "\n",
    "train_x, train_y = MNIST.traindata(1:train_size);\n",
    "test_x, test_y  = MNIST.testdata();\n",
    "\n",
    "labels = one_hot_encoding(train_y)\n",
    "test_labels = one_hot_encoding(test_y)\n",
    "\n",
    "α, iterations = 0.1, 201\n",
    "hidden_size, pixels_per_image, num_labels = 128, 28 * 28, 10\n",
    "batch_size = 100\n",
    "\n",
    "weights₀ = 0.2 * rand(Float16, (pixels_per_image, hidden_size)) .- 0.1\n",
    "weights₁ = 0.2 * rand(Float16, (hidden_size, num_labels)) .- 0.1\n",
    "\n",
    "relu(x) = (x > 0) * x\n",
    "\n",
    "relu2deriv(output) = output > 0\n",
    "\n",
    "for epoch in 1:iterations\n",
    "    error, correct = 0, 0\n",
    "    for i in 1:batch_size:train_size\n",
    "        layer₀ = reshape(train_x[:, :, i:i + batch_size - 1], (28*28, batch_size))'\n",
    "        label = labels[:, i:i + batch_size - 1]'\n",
    "\n",
    "        layer₁ = relu.(layer₀ * weights₀)\n",
    "        p = Binomial(1, 0.5)\n",
    "        dropout_mask = rand(p, size(layer₁))\n",
    "        layer₁ = (layer₁ .* dropout_mask) .* 2\n",
    "        layer₂ = layer₁ * weights₁\n",
    "\n",
    "        # @show size(layer₀) size(layer₁) size(layer₂) size(weights₀) size(weights₁)\n",
    "        error += sum(( label - layer₂ ) .^ 2)\n",
    "        correct += sum(convert.(Int, argmax(layer₂, dims=2) .== argmax(label, dims=2)))\n",
    "        layer₂∇ = (label - layer₂) ./ batch_size\n",
    "        layer₁∇ = (layer₂∇ * weights₁') .* relu2deriv.(layer₁)\n",
    "        layer₁∇ = layer₁∇ .* dropout_mask\n",
    "        weights₁ += α * (layer₁' * layer₂∇)\n",
    "        weights₀ += α * (layer₀' * layer₁∇)\n",
    "    end\n",
    "\n",
    "    if rem(epoch, 50) == 0\n",
    "        println(\"=== Epoch $(epoch)\")\n",
    "        test_size = 5000\n",
    "        correct /= train_size\n",
    "        error /= train_size\n",
    "        @show error correct\n",
    "        test_error, test_correct = (0.0, 0)\n",
    "        for i in 1:test_size\n",
    "            layer₀ = reshape(test_x[:, :, i], 1, 28*28)\n",
    "            label = test_labels[:, i]'\n",
    "            layer₁ = relu.(layer₀ * weights₀)\n",
    "            layer₂ = layer₁ * weights₁\n",
    "            test_error += sum(( label - layer₂ ) .^ 2)\n",
    "            test_correct += convert(Int, argmax(layer₂) == argmax(label))\n",
    "        end\n",
    "        test_error /= test_size\n",
    "        test_correct /= test_size\n",
    "        @show test_error test_correct\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2518b53f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict = Any[4, 9, 2, 1, 6, 1, 0, 7, 3, 3, 7, 4, 2, 3, 0, 5]\n",
      "label = Any[4, 9, 2, 1, 6, 1, 0, 9, 3, 3, 7, 9, 2, 3, 0, 5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "28×448 MosaicView{Gray{N0f8}, 4, Base.ReshapedArray{Gray{N0f8}, 4, PaddedView{Gray{N0f8}, 3, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}, Base.OneTo{Int64}}, StackViews.StackView{Gray{N0f8}, 3, 3, Vector{OffsetArrays.OffsetMatrix{Gray{N0f8}, PaddedView{Gray{N0f8}, 2, Tuple{UnitRange{Int64}, UnitRange{Int64}}, Base.ReinterpretArray{Gray{N0f8}, 2, N0f8, Matrix{N0f8}, true}}}}}}, Tuple{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}, Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}}}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function test_model(image)\n",
    "    layer₀ = reshape(image, 1, 28*28)\n",
    "    layer₁ = relu.(layer₀ * weights₀)\n",
    "    layer₂ = layer₁ * weights₁\n",
    "    argmax(layer₂)[2] - 1\n",
    "end\n",
    "\n",
    "n = rand(1:10000, 16)\n",
    "grid = [\n",
    "    MNIST.convert2image(test_x[:, :, i])\n",
    "    for i in n\n",
    "]\n",
    "predict, label = [], []\n",
    "\n",
    "for i in n\n",
    "    push!(predict, test_model(test_x[:, :, i]))\n",
    "    push!(label, onecold(test_labels[:, i]) - 1)\n",
    "end\n",
    "\n",
    "@show predict label\n",
    "\n",
    "mosaicview(grid; nrow=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2687809",
   "metadata": {},
   "source": [
    "### Upgrading the MNIST network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389e7357",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 20\n",
      "error = 0.6190143302898572\n",
      "correct = 0.753\n",
      "test_error = 2.650810194516497\n",
      "test_correct = 0.7221\n",
      "=== Epoch 40\n",
      "error = 0.3953942164833337\n",
      "correct = 0.822\n",
      "test_error = 11.155884094838054\n",
      "test_correct = 0.7859\n",
      "=== Epoch 60\n",
      "error = 0.2904212420385567\n",
      "correct = 0.862\n",
      "test_error = 20.351821856372\n",
      "test_correct = 0.8177\n",
      "=== Epoch 80\n",
      "error = 0.23761920310625867\n",
      "correct = 0.874\n",
      "test_error = 28.633479336521763\n",
      "test_correct = 0.8324\n",
      "=== Epoch 100\n",
      "error = 0.2026168553027372\n",
      "correct = 0.892\n",
      "test_error = 36.10451605569889\n",
      "test_correct = 0.8422\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using MLDatasets\n",
    "using ImageCore\n",
    "using Distributions\n",
    "\n",
    "p = Binomial(1, 0.5)\n",
    "\n",
    "one_hot_encoding(x) = Flux.onehotbatch(x, 0:9)\n",
    "train_size = 1000\n",
    "\n",
    "train_x, train_y = MNIST.traindata(1:train_size);\n",
    "test_x, test_y  = MNIST.testdata();\n",
    "\n",
    "labels = one_hot_encoding(train_y)\n",
    "test_labels = one_hot_encoding(test_y)\n",
    "\n",
    "α, iterations = 2, 101\n",
    "hidden_size, pixels_per_image, num_labels = 128, 28 * 28, 10\n",
    "batch_size = 100\n",
    "\n",
    "weights₀ = 0.02 * rand(Float32, (pixels_per_image, hidden_size)) .- 0.01\n",
    "weights₁ = 0.2 * rand(Float32, (hidden_size, num_labels)) .- 0.1\n",
    "\n",
    "tanh2deriv(output) = 1 - (output ^ 2)\n",
    "\n",
    "for epoch in 1:iterations\n",
    "    error, correct = 0, 0\n",
    "    for i in 1:batch_size:train_size\n",
    "        layer₀ = reshape(train_x[:, :, i:i + batch_size - 1], (28*28, batch_size))'\n",
    "        label = labels[:, i:i + batch_size - 1]'\n",
    "\n",
    "        layer₁ = tanh.(layer₀ * weights₀)\n",
    "        dropout_mask = rand(p, size(layer₁))\n",
    "        layer₁ = (layer₁ .* dropout_mask) .* 2\n",
    "        layer₂ = softmax(layer₁ * weights₁, dims=2)\n",
    "        # @show size(layer₀) size(layer₁) size(layer₂) size(weights₀) size(weights₁)\n",
    "        error += sum(( label - layer₂ ) .^ 2)\n",
    "        correct += sum(convert.(Int, argmax(layer₂, dims=2) .== argmax(label, dims=2)))\n",
    "        layer₂∇ = (label - layer₂) ./ (batch_size * size(layer₁)[1])\n",
    "        layer₁∇ = (layer₂∇ * weights₁') .* tanh2deriv.(layer₁)\n",
    "        layer₁∇ = layer₁∇ .* dropout_mask\n",
    "        weights₁ += α * (layer₁' * layer₂∇)\n",
    "        weights₀ += α * (layer₀' * layer₁∇)\n",
    "    end\n",
    "\n",
    "    if rem(epoch, 20) == 0\n",
    "        println(\"=== Epoch $(epoch)\")\n",
    "        test_size = 10000\n",
    "        correct /= train_size\n",
    "        error /= train_size\n",
    "        @show error correct\n",
    "        test_error, test_correct = (0.0, 0)\n",
    "        for i in 1:test_size\n",
    "            layer₀ = reshape(test_x[:, :, i], 1, 28*28)\n",
    "            label = test_labels[:, i]'\n",
    "            layer₁ = tanh.(layer₀ * weights₀)\n",
    "            layer₂ = layer₁ * weights₁\n",
    "            test_error += sum(( label - layer₂ ) .^ 2)\n",
    "            test_correct += convert(Int, argmax(layer₂) == argmax(label))\n",
    "        end\n",
    "        test_error /= test_size\n",
    "        test_correct /= test_size\n",
    "        @show test_error test_correct\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "640b6f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict = Any[4, 1, 2, 4, 1, 9, 6, 7, 5, 6, 4, 0, 5, 7, 1, 5]\n",
      "label = Any[4, 1, 2, 4, 1, 5, 6, 7, 5, 6, 4, 0, 3, 7, 1, 5]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "28×448 MosaicView{Gray{N0f8}, 4, Base.ReshapedArray{Gray{N0f8}, 4, PaddedView{Gray{N0f8}, 3, Tuple{Base.OneTo{Int64}, Base.OneTo{Int64}, Base.OneTo{Int64}}, StackViews.StackView{Gray{N0f8}, 3, 3, Vector{OffsetArrays.OffsetMatrix{Gray{N0f8}, PaddedView{Gray{N0f8}, 2, Tuple{UnitRange{Int64}, UnitRange{Int64}}, Base.ReinterpretArray{Gray{N0f8}, 2, N0f8, Matrix{N0f8}, true}}}}}}, Tuple{Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}, Base.MultiplicativeInverses.SignedMultiplicativeInverse{Int64}}}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Flux: onecold\n",
    "using Images\n",
    "\n",
    "function test_model(image)\n",
    "    layer₀ = reshape(image, 1, 28*28)\n",
    "    layer₁ = tanh.(layer₀ * weights₀)\n",
    "    layer₂ = layer₁ * weights₁\n",
    "    argmax(layer₂)[2] - 1\n",
    "end\n",
    "\n",
    "n = rand(1:10000, 16)\n",
    "grid = [\n",
    "    MNIST.convert2image(test_x[:, :, i])\n",
    "    for i in n\n",
    "]\n",
    "predict, label = [], []\n",
    "\n",
    "for i in n\n",
    "    push!(predict, test_model(test_x[:, :, i]))\n",
    "    push!(label, onecold(test_labels[:, i]) - 1)\n",
    "end\n",
    "\n",
    "@show predict label\n",
    "\n",
    "mosaicview(grid; nrow=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d646dbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CUDA\n",
    "CUDA.functional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36424da6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using Flux, Statistics\n",
    "using Flux.Data: DataLoader\n",
    "using Flux: onehotbatch, onecold, @epochs\n",
    "using Flux.Losses: logitcrossentropy\n",
    "using Base: @kwdef\n",
    "using Statistics\n",
    "using MLDatasets\n",
    "using ImageCore\n",
    "using CUDA\n",
    "using BenchmarkTools\n",
    "\n",
    "α, iterations = 2, 201\n",
    "hidden_size, pixels_per_image, num_labels = 128, 28 * 28, 10\n",
    "batch_size = 100\n",
    "\n",
    "one_hot_encoding(x) = Flux.onehotbatch(x, 0:9)\n",
    "train_size = 2500\n",
    "\n",
    "train_x, train_y = MNIST.traindata(1:train_size);\n",
    "test_x, test_y  = MNIST.testdata();\n",
    "\n",
    "x_train, x_test = Flux.flatten(train_x), Flux.flatten(test_x)\n",
    "labels, test_labels = one_hot_encoding(train_y), one_hot_encoding(test_y)\n",
    "\n",
    "train_loader = Flux.DataLoader((x_train, labels), batchsize=batch_size, shuffle=true)\n",
    "test_loader = Flux.DataLoader((x_test, test_labels), batchsize=batch_size)\n",
    "\n",
    "\n",
    "@show CUDA.functional()\n",
    "CUDA.allowscalar(false)\n",
    "device = gpu\n",
    "\n",
    "function loss_and_accuracy(data_loader, model, device)\n",
    "    acc = 0\n",
    "    ls = 0.0f0\n",
    "    num = 0\n",
    "    for (x, y) in data_loader\n",
    "        x, y = device(x), device(y)\n",
    "        ŷ = model(x)\n",
    "        ls += logitcrossentropy(ŷ, y, agg=sum)\n",
    "        acc += sum(onecold(ŷ) .== onecold(y))\n",
    "        num +=  size(x)[end]\n",
    "    end\n",
    "    return ls / num, acc / num\n",
    "end\n",
    "\n",
    "model = Chain(\n",
    "    Dense(784, hidden_size, Flux.relu),\n",
    "    Dense(hidden_size, num_labels)\n",
    ") |> device\n",
    "\n",
    "ps = Flux.params(model)\n",
    "opt = ADAM(0.0003)\n",
    "\n",
    "\n",
    "for epoch in 1:iterations\n",
    "    for (x, y) in train_loader\n",
    "        x, y = device(x), device(y)\n",
    "        gs = gradient(() -> logitcrossentropy(model(x), y), ps)\n",
    "        Flux.Optimise.update!(opt, ps, gs)\n",
    "    end\n",
    "\n",
    "    train_loss, train_acc = loss_and_accuracy(train_loader, model, device)\n",
    "    test_loss, test_acc = loss_and_accuracy(test_loader, model, device)\n",
    "    if rem(epoch, 50) == 0\n",
    "        println(\"Epoch=$epoch\")\n",
    "        println(\"  train_loss = $train_loss, train_accuracy = $train_acc\")\n",
    "        println(\"  test_loss = $test_loss, test_accuracy = $test_acc\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c8426",
   "metadata": {},
   "source": [
    "## Neural network that understand language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12aa87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"reviews.txt\")\n",
    "raw_reviews = filter.(x -> length(x) > 0, unique.(split.(readlines(f), \" \")))\n",
    "close(f)\n",
    "\n",
    "f = open(\"labels.txt\")\n",
    "raw_labels = readlines(f)\n",
    "close(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ba7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = unique(reduce(vcat, raw_reviews))\n",
    "word2index = Dict(v => i for (i, v) in enumerate(vocab))\n",
    "input_dataset = map.(x -> word2index[x], raw_reviews)\n",
    "labels = map(x -> (x == \"positive\") ? 1 : 0, raw_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee731596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch 1\n",
      "correct / total = 0.833875\n",
      "test_correct / test_total = 0.9093333333333333\n",
      "=== Epoch 2\n",
      "correct / total = 0.8998333333333334\n",
      "test_correct / test_total = 0.9311666666666667\n",
      "=== Epoch 3\n",
      "correct / total = 0.9201666666666667\n",
      "test_correct / test_total = 0.9441666666666667\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "\n",
    "train_size = 24000\n",
    "\n",
    "α, iterations, hidden_size, batch_size = 0.01, 3, 100, 100\n",
    "\n",
    "weights₀ = 0.2 * rand(Float32, (length(vocab), hidden_size)) .- 0.1\n",
    "weights₁ = 0.2 * rand(Float32, (hidden_size, 1)) .- 0.1\n",
    "\n",
    "\n",
    "for epoch in 1:iterations\n",
    "    total, correct = 0, 0\n",
    "    for i in 1:train_size\n",
    "        x, y = input_dataset[i], labels[i]\n",
    "        \n",
    "        layer₁ = sigmoid.(sum(weights₀[x, :], dims=1))\n",
    "        layer₂ = sum(sigmoid.(layer₁ * weights₁))\n",
    "        layer₂∇ = layer₂ - y\n",
    "        layer₁∇ = layer₂∇ * weights₁'\n",
    "        weights₀[x, :] .-= layer₁∇ * α\n",
    "        weights₁ -= (layer₁' * layer₂∇) * α\n",
    "        \n",
    "        if abs(layer₂∇) < 0.5\n",
    "            correct += 1\n",
    "        end\n",
    "        total += 1\n",
    "    end\n",
    "\n",
    "    if rem(epoch, 10) != 0\n",
    "        println(\"=== Epoch $(epoch)\")\n",
    "        @show correct / total\n",
    "        test_total, test_correct = (0.0, 0)\n",
    "        for i in 1:train_size\n",
    "            x, y = input_dataset[i], labels[i]\n",
    "\n",
    "            layer₁ = sigmoid.(sum(weights₀[x, :], dims=1))\n",
    "            layer₂ = sum(sigmoid.(layer₁ * weights₁))\n",
    "            if abs(layer₂ - y) < 0.5\n",
    "                test_correct += 1\n",
    "            end\n",
    "            test_total += 1\n",
    "        end\n",
    "        @show test_correct / test_total\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0611bde",
   "metadata": {},
   "source": [
    "### Comparing word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9a401f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15-element Vector{Pair{Any, Any}}:\n",
       "   \"beautiful\" => -0.0\n",
       "      \"lonely\" => -0.7056556329625407\n",
       " \"recommended\" => -0.7078083581416031\n",
       " \"spectacular\" => -0.7111706962582793\n",
       "       \"magic\" => -0.7126587491451116\n",
       "       \"marie\" => -0.7391234313687798\n",
       "      \"worlds\" => -0.7488965394581588\n",
       "         \"bit\" => -0.7497769035517885\n",
       "     \"freedom\" => -0.7600134527197082\n",
       "    \"flawless\" => -0.7630605198702134\n",
       "  \"underrated\" => -0.7642487332774035\n",
       "        \"best\" => -0.7654467655313637\n",
       "   \"subtitles\" => -0.7681777644865341\n",
       "       \"heart\" => -0.7722322816952291\n",
       "     \"certain\" => -0.7746179427000939"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function similar(target=\"beautiful\", len=10)\n",
    "    target_index = word2index[target]\n",
    "    scores = Dict()\n",
    "    for (word, index) in word2index\n",
    "        ∇ = weights₀[index, :] - weights₀[target_index, :]\n",
    "        ∇² = ∇ .^ 2\n",
    "        scores[word] = -sqrt(sum(∇²))\n",
    "    end\n",
    "    sort(collect(scores), by=x -> x[2], rev=true)[1:len]\n",
    "end\n",
    "\n",
    "similar(\"beautiful\", 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c77a9910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20-element Vector{Pair{Any, Any}}:\n",
       "   \"excellent\" => -0.0\n",
       "     \"amazing\" => -0.783072247434673\n",
       " \"wonderfully\" => -0.815343526144588\n",
       "     \"perfect\" => -0.8190406439823616\n",
       "        \"rare\" => -0.8199391127254688\n",
       "  \"incredible\" => -0.8300515343199132\n",
       "        \"noir\" => -0.8414920201502964\n",
       "   \"wonderful\" => -0.8464807060644697\n",
       "      \"superb\" => -0.8643986063688696\n",
       "       \"loved\" => -0.8905058149461618\n",
       "  \"refreshing\" => -0.8954279358300526\n",
       "   \"enjoyable\" => -0.8965530446981935\n",
       "       \"today\" => -0.8980784862582105\n",
       "   \"perfectly\" => -0.9398194042677067\n",
       "         \"gem\" => -0.9537147370213367\n",
       "    \"funniest\" => -0.9720811391636802\n",
       " \"fascinating\" => -0.9779250115548829\n",
       "      \"highly\" => -0.9815329198755685\n",
       "    \"favorite\" => -1.0087843929478575\n",
       "       \"solid\" => -1.0254972511338174"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar(\"excellent\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a9a5802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Pair{Any, Any}}:\n",
       "          \"awful\" => -0.0\n",
       "         \"poorly\" => -0.7705812653972363\n",
       "          \"waste\" => -0.8442135471653316\n",
       " \"disappointment\" => -0.9326396910457765\n",
       "          \"worst\" => -0.9834540776291226\n",
       "  \"disappointing\" => -1.002170864614918\n",
       "          \"lacks\" => -1.058728084663763\n",
       "           \"dull\" => -1.1268992238986413\n",
       "          \"fails\" => -1.187673129960059\n",
       "         \"boring\" => -1.1899847943726"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar(\"awful\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f0183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5106babc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03338249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e5200f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83b548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f722601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb77164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff30509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d3694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb2601c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e0b01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4285f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0362e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24616c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdc40e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab7e23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
